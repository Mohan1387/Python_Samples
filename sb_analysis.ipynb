{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import pyodbc\n",
    "import cx_Oracle\n",
    "\n",
    "from lifelines.plotting import plot_lifetimes      # Lifeline package for the Survival Analysis\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(12,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = '172.16.80.74'\n",
    "port = '1521'\n",
    "SID = 'RPTDB'\n",
    "\n",
    "dsn_tns = cx_Oracle.makedsn(ip, port, SID)\n",
    "connection = cx_Oracle.connect('ANLYUSR', 'ANLYUSR$', dsn_tns)\n",
    "\n",
    "query = \"SELECT /*+ PARALLEL(10) */ \\\n",
    "TB1.AGMTNO,TB1.AGMT_DATE,TB1.PORTFOLIO,TB1.CHANNEL, \\\n",
    "TB1.PAYMENT_TYPE,TB1.AREA_CODE,TB1.DEALER_TYPE,TB1.DEALER_CODE,TB1.MAINDEALER_CODE, \\\n",
    "TB1.EXECUTIVE_CODE,TB1.PRODUCT_CODE,TB1.MODEL_CODE,TB1.SCHEME_TYPE, \\\n",
    "TB1.SCHEME_CODE,TB1.ADVANCE_EMI_COUNT,TB1.TENUR,TB1.ROI, \\\n",
    "TB1.EMI,TB1.PORCESSING_FEE,TB1.STAMPING_CHARGES,TB1.ASSET_COST, \\\n",
    "TB1.LOAN_AMOUNT,TB1.DOWN_PAYMENT,TB1.INITITAL_HIRE,TB1.LTV,TB1.AMORT_IRR,TB1.CUSTOMER_IRR, \\\n",
    "TB1.NET_IRR,TB1.VECHICAL_INSURANCE_AMT,TB1.SPECIAL_INSURANCE,TB1.SPECIAL_INSURANCE_FOR, \\\n",
    "TB1.SPECIAL_INSURANCE_PRODUCT,TB1.SPECIAL_INSURANCE_AMOUNT, \\\n",
    "TB1.GENDER,TB1.PANNO,TB1.DRIVING_LICENSE,TB1.PASSPORT,TB1.AADHAR,TB1.RATION, \\\n",
    "TB1.EXISTING_CUSTOMER,TB1.EMPLOYMENT_TYPE,TB1.CUSTOMER_PROFILE_CODE,TB1.RESIDENT_TYPE, \\\n",
    "TB1.BANK_ACCOUNT,TB1.PINCODE,TB1.CITY,TB1.TALUK,TB1.TOWN,TB1.STATE, \\\n",
    "TB1.TRN_MONTH,TB1.TRN_YEAR,TB1.FIN_YEAR,TB1.PRODUCT_TYPE,TB1.ACTUAL_LOAN_AMOUNT, \\\n",
    "TB1.PRODUCT_CUST_IRR,TB1.PRODUCT_AMORT_IRR,TB1.PRODUCT_TENUR,TB1.PF_SERVICE_TAX, \\\n",
    "TB1.SUB_LOCATION,TB1.MICRO_MARKET,TB1.CIBIL_SCORE,TB1.COBORROWER, \\\n",
    "TB1.GUARANTOR,TB1.RELIGION,TB1.CIBIL_HIT,TB1.CIBIL_OVERDUE, \\\n",
    "TB1.CIBIL_SCORE_COBORROWER,TB1.CIBIL_SCORE_GURANTOR, \\\n",
    "TB1.LAST_EMI_DATE - TB1.FIRST_EMI_DATE as duration_days, \\\n",
    "TB1.STATUS,TB1.ADDRESS_TYPE, \\\n",
    "TB1.ADDRESS_SLNO,TB1.SUB_STATUS,TB2.MOB, \\\n",
    "round((TB1.AGMT_DATE - TB1.DOB)/365) as AGE FROM TBL_TRN_CUSTOMER_DETAILS TB1 LEFT OUTER JOIN \\\n",
    "(SELECT TBL1.AGMTNO,TBL1.MOB,TBL1.CLOSING_BUCKET FROM \\\n",
    "(SELECT AGMTNO,MOB,CLOSING_BUCKET, \\\n",
    "DENSE_RANK() OVER (PARTITION BY AGMTNO ORDER BY MOB) AS MOBRANK \\\n",
    "FROM TBL_TRN_COLLECTION_DETAILS \\\n",
    "WHERE CLOSING_BUCKET = 1 \\\n",
    "AND MOB <> 0) TBL1 \\\n",
    "where TBL1.mobrank = 1) TB2 \\\n",
    "ON TB1.AGMTNO = TB2.AGMTNO \\\n",
    "AND TB1.AGMTNO is not null \\\n",
    "AND TB1.PORTFOLIO = 'TW' \\\n",
    "AND TB1.CHASSIS_NUMBER is not null\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data to delete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    del Data\n",
    "    del data\n",
    "except:\n",
    "    print(\"No data to delete\")\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_sql(query, con=connection, chunksize=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "decoding with 'WINDOWS-1252' codec failed (KeyboardInterrupt: )",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\trainingenv\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, errors)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'strict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2c48ab6ba968>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchunk\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mData\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#data = pd.read_csv(\"D:\\cust_bounce_data_v1.csv\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-2c48ab6ba968>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchunk\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mData\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#data = pd.read_csv(\"D:\\cust_bounce_data_v1.csv\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\trainingenv\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36m_query_iterator\u001b[1;34m(cursor, chunksize, columns, index_col, coerce_float, parse_dates)\u001b[0m\n\u001b[0;32m   1396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1397\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1398\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetchmany\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1399\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1400\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: decoding with 'WINDOWS-1252' codec failed (KeyboardInterrupt: )"
     ]
    }
   ],
   "source": [
    "data = pd.concat([chunk for chunk in Data])\n",
    "#data = pd.read_csv(\"D:\\cust_bounce_data_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info(max_cols=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"D:\\cust_bounce_data_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.columns:\n",
    "    #if data[i].isnull().sum() != 0:\n",
    "    print(\"column {} has ---unique----> {} ---null----> {} \".format(i,data[i].unique().size, data[i].isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['AGMTNO', 'AGMT_DATE', 'PORTFOLIO', 'CHANNEL', 'PAYMENT_TYPE',\n",
    "       'AREA_CODE', 'DEALER_TYPE', 'DEALER_CODE', 'MAINDEALER_CODE',\n",
    "       'EXECUTIVE_CODE', 'PRODUCT_CODE', 'MODEL_CODE', 'SCHEME_TYPE',\n",
    "       'SCHEME_CODE', 'ADVANCE_EMI_COUNT', 'TENUR', 'ROI', 'EMI',\n",
    "       'PORCESSING_FEE', 'STAMPING_CHARGES', 'ASSET_COST', 'LOAN_AMOUNT',\n",
    "       'DOWN_PAYMENT', 'INITITAL_HIRE', 'LTV', 'AMORT_IRR', 'CUSTOMER_IRR',\n",
    "       'NET_IRR', 'VECHICAL_INSURANCE_AMT', 'SPECIAL_INSURANCE',\n",
    "       'SPECIAL_INSURANCE_FOR', 'SPECIAL_INSURANCE_PRODUCT',\n",
    "       'SPECIAL_INSURANCE_AMOUNT', 'GENDER', 'PANNO', 'DRIVING_LICENSE',\n",
    "       'PASSPORT', 'AADHAR', 'RATION', 'EXISTING_CUSTOMER', 'EMPLOYMENT_TYPE',\n",
    "       'CUSTOMER_PROFILE_CODE', 'RESIDENT_TYPE', 'BANK_ACCOUNT', 'PINCODE',\n",
    "       'CITY', 'STATE', 'TRN_MONTH', 'TRN_YEAR', 'FIN_YEAR',\n",
    "       'ACTUAL_LOAN_AMOUNT', 'PRODUCT_CUST_IRR',\n",
    "       'PRODUCT_AMORT_IRR', 'PRODUCT_TENUR', 'PF_SERVICE_TAX',\n",
    "       'CIBIL_SCORE', 'COBORROWER', 'GUARANTOR', 'RELIGION',\n",
    "       'CIBIL_HIT', 'CIBIL_OVERDUE', 'CIBIL_SCORE_COBORROWER',\n",
    "       'CIBIL_SCORE_GURANTOR', 'LAST_EMI_DATE','FIRST_EMI_DATE', 'STATUS', 'ADDRESS_TYPE',\n",
    "       'ADDRESS_SLNO', 'SUB_STATUS', 'DOB']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.CHANNEL.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.MODEL_CODE.notnull()]\n",
    "data = data[data.SCHEME_TYPE.notnull()]\n",
    "data = data[data.DOWN_PAYMENT.notnull()]\n",
    "data = data[data.ROI.notnull()]\n",
    "data = data[data.GENDER.notnull()]\n",
    "data = data[data.EMPLOYMENT_TYPE.notnull()]\n",
    "data = data[data.CUSTOMER_PROFILE_CODE.notnull()]\n",
    "data = data[data.CITY.notnull()]\n",
    "data = data[data.RELIGION.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['VECHICAL_INSURANCE_AMT'].fillna(0, inplace=True)\n",
    "data['SPECIAL_INSURANCE_FOR'].fillna('N/A', inplace=True)\n",
    "data['SPECIAL_INSURANCE_PRODUCT'].fillna('N/A', inplace=True)\n",
    "data['SPECIAL_INSURANCE_AMOUNT'].fillna(0, inplace=True)\n",
    "data['EXISTING_CUSTOMER'].fillna('N/A', inplace=True)\n",
    "data['RESIDENT_TYPE'].fillna('N/A', inplace=True)\n",
    "data['CIBIL_SCORE'].fillna(0, inplace=True)\n",
    "data['CIBIL_HIT'].fillna('N/A', inplace=True)\n",
    "data['CIBIL_SCORE_COBORROWER'].fillna(0, inplace=True)\n",
    "data['CIBIL_SCORE_GURANTOR'].fillna(0, inplace=True)\n",
    "data['SUB_STATUS'].fillna('L', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.AGE.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['ID'] = pd.factorize(df.SrcIP)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['trgt'] = data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_string_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.columns:\n",
    "    if is_string_dtype(data[i]):\n",
    "        data[i] = pd.factorize(data[i])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v1 = data[['PORTFOLIO', 'CHANNEL', 'PAYMENT_TYPE',\n",
    "       'AREA_CODE', 'DEALER_TYPE', 'DEALER_CODE', 'MAINDEALER_CODE',\n",
    "       'EXECUTIVE_CODE', 'PRODUCT_CODE', 'MODEL_CODE', 'SCHEME_TYPE',\n",
    "       'SCHEME_CODE', 'ADVANCE_EMI_COUNT', 'TENUR', 'ROI', 'EMI',\n",
    "       'PORCESSING_FEE', 'STAMPING_CHARGES', 'ASSET_COST', 'LOAN_AMOUNT',\n",
    "       'DOWN_PAYMENT', 'INITITAL_HIRE', 'LTV', 'AMORT_IRR', 'CUSTOMER_IRR',\n",
    "       'NET_IRR', 'VECHICAL_INSURANCE_AMT', 'SPECIAL_INSURANCE',\n",
    "       'SPECIAL_INSURANCE_FOR', 'SPECIAL_INSURANCE_PRODUCT',\n",
    "       'SPECIAL_INSURANCE_AMOUNT', 'GENDER', 'PANNO', 'DRIVING_LICENSE',\n",
    "       'PASSPORT', 'AADHAR', 'RATION', 'EXISTING_CUSTOMER', 'EMPLOYMENT_TYPE',\n",
    "       'CUSTOMER_PROFILE_CODE', 'RESIDENT_TYPE', 'BANK_ACCOUNT', 'PINCODE',\n",
    "       'CITY', 'STATE', 'TRN_MONTH', 'TRN_YEAR', 'FIN_YEAR',\n",
    "       'ACTUAL_LOAN_AMOUNT', 'PRODUCT_CUST_IRR',\n",
    "       'PRODUCT_AMORT_IRR', 'PRODUCT_TENUR', 'PF_SERVICE_TAX',\n",
    "       'CIBIL_SCORE', 'COBORROWER', 'GUARANTOR', 'RELIGION',\n",
    "       'CIBIL_HIT', 'CIBIL_OVERDUE', 'CIBIL_SCORE_COBORROWER',\n",
    "       'CIBIL_SCORE_GURANTOR', 'DURATION_DAYS', 'STATUS', 'ADDRESS_TYPE',\n",
    "       'ADDRESS_SLNO', 'SUB_STATUS', 'FIRST_BOUNCE_MOB', 'AGE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import CoxPHFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Cox Proportional Hazards model\n",
    "cph = CoxPHFitter()   ## Instantiate the class to create a cph object\n",
    "cph.fit(data_v1, 'tenure', event_col='Churn')   ## Fit the data to train the model\n",
    "cph.print_summary()    ## HAve a look at the significance of the features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
